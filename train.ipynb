{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3b8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2fa85",
   "metadata": {},
   "source": [
    "# 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edfd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=8000\n",
    "context_length=256\n",
    "d_model=768\n",
    "d_ff=3072\n",
    "theta=1000\n",
    "num_layers=6\n",
    "num_heads=12\n",
    "device=torch.device('cuda')\n",
    "dtype=torch.bfloat16\n",
    "batch_size=32\n",
    "lr=3e-4\n",
    "weight_decay=0.01\n",
    "epoch=1000\n",
    "grad_clip=1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192bd51a",
   "metadata": {},
   "source": [
    "# 读取文本并生成BPEtokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57933e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path='shakespear.txt'\n",
    "with open(text_path,'r',encoding='utf-8') as f:\n",
    "    text_example=f.read()\n",
    "vocab,merge=run_train_bpe(text_path,vocab_size,['<|endoftext|>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b52dc4",
   "metadata": {},
   "source": [
    "# 生成训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_vocab_merges(vocab,merge,'BPE')\n",
    "tokenizer=get_tokenizer(vocab,merge,['<|endoftext|>'])\n",
    "np_lst=np.array(tokenizer.encode(text_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1026bf2",
   "metadata": {},
   "source": [
    "# 生成模型和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e186fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=TransformerLM(vocab_size,d_model,num_layers,num_heads,d_ff,context_length,theta,device,dtype)\n",
    "AdamW=get_adamw_cls()\n",
    "optimizer=AdamW(params=model.parameters(),weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fca9ce",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdd7ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#faster version\n",
    "model.train()\n",
    "for i in range(epoch):\n",
    "    input,label=run_get_batch(np_lst,batch_size,context_length,device)\n",
    "    optimizer.zero_grad()\n",
    "    output=model(input)\n",
    "    loss=run_cross_entropy(output.reshape(-1,vocab_size),label.reshape(-1))\n",
    "    loss.backward()\n",
    "    run_gradient_clipping(model.parameters(),grad_clip)\n",
    "    optimizer.step()\n",
    "    if (i+1)%100==0:\n",
    "        print(f'train {i+1} times loss: {loss}')\n",
    "        run_save_checkpoint(model,optimizer,i//100,'state_dict.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f8223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#better version\n",
    "model.train()\n",
    "max_learning_rate = 3e-4    # 最大学习率（适配d_model=768的模型）\n",
    "min_learning_rate = 1e-5    # 最小学习率（防止学习率过低导致停止更新）\n",
    "warmup_iters = 1000         # 预热迭代数（前1000步线性升温）\n",
    "cosine_cycle_iters = 50000  # 余弦退火总迭代数（预热后到50000步完成退火）\n",
    "grad_clip = 1.0             # 梯度裁剪阈值\n",
    "epoch = 50000      \n",
    "for i in range(epoch):\n",
    "    input, label = run_get_batch(np_lst, batch_size, context_length, device)\n",
    "    current_lr = run_get_lr_cosine_schedule(\n",
    "        it=i,\n",
    "        max_learning_rate=max_learning_rate,\n",
    "        min_learning_rate=min_learning_rate,\n",
    "        warmup_iters=warmup_iters,\n",
    "        cosine_cycle_iters=cosine_cycle_iters\n",
    "    )\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = current_lr\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input)\n",
    "    loss = run_cross_entropy(output.reshape(-1, vocab_size), label.reshape(-1))\n",
    "    loss.backward()\n",
    "    run_gradient_clipping(model.parameters(), grad_clip)\n",
    "    optimizer.step()\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f'Iteration {i+1} | Loss: {loss.item():.4f} | Current LR: {current_lr:.6f}')\n",
    "        run_save_checkpoint(model, optimizer, (i+1)//100, 'state_dict.pt')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
